{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import random\n",
    "import pickle\n",
    "import operator\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "random.seed(3407)\n",
    "np.random.seed(3407)\n",
    "torch.manual_seed(3407)\n",
    "torch.cuda.manual_seed(3407)\n",
    "torch.cuda.manual_seed_all(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
    "                        'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax',\n",
    "                        'Consolidation', 'Edema', 'Emphysema', 'Fibrosis',\n",
    "                        'Pleural']\n",
    "def imageToLabel(image_name):\n",
    "    labels = image_name.split('_')[2].split('|')\n",
    "    #print(labels)\n",
    "    label = [1 if dis in labels else 0 for dis in classes]\n",
    "    return np.array(label)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "def imageDetails(image_path):\n",
    "    image_name = image_path.split('/')[-1]\n",
    "    label_string = image_name.split('_')[2].split('|')\n",
    "    #print(label_string)\n",
    "    label_string = [la[:3] for la in label_string]\n",
    "    image_label = imageToLabel(image_name)\n",
    "    image = np.load(image_path)\n",
    "    '''plt.imshow(image, 'gray')\n",
    "    plt.title(label_string, fontsize=21)\n",
    "    plt.axis('off')\n",
    "    plt.show()'''\n",
    "    if len(image.shape)!= 2:\n",
    "        image = np.mean(image,axis=-1)\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "    tensor_image = transform(image).unsqueeze(0).cuda()\n",
    "    return image_label, tensor_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming Distance Learing During Training (Table 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_path = './Dataset/train/trainChest_X-ray_Atelectasis|Consolidation|Effusion|Infiltration_46292.npy'\n",
    "x_2_path= './Dataset/train/trainChest_X-ray_Atelectasis|Consolidation|Infiltration|Pneumonia_55941.npy'\n",
    "x_3_path= './Dataset/train/trainChest_X-ray_Consolidation|Effusion|Infiltration_17699.npy'\n",
    "x_4_path= './Dataset/train/trainChest_X-ray_Effusion|Infiltration_99837.npy'\n",
    "x_5_path= './Dataset/train/trainChest_X-ray_Atelectasis|Consolidation|Effusion_5787.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1, x_1 = imageDetails(x_1_path)\n",
    "y_2, x_2 = imageDetails(x_2_path)\n",
    "y_3, x_3 = imageDetails(x_3_path)\n",
    "y_4, x_4 = imageDetails(x_4_path)\n",
    "y_5, x_5 = imageDetails(x_5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(hash_code):\n",
    "    encoder = Encoder(len(classes),hash_code)\n",
    "    if torch.cuda.is_available():\n",
    "        encoder.cuda()\n",
    "    model_name = f'JaccHash_{hash_code}.pkl'\n",
    "    dataStorePath = './Datastore/Models/'\n",
    "    model_path = os.path.join(dataStorePath,model_name)\n",
    "    #print(model_path)\n",
    "    encoder.load_state_dict(torch.load(model_path))\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HDCompare(image, image1, labels, labels1, hash_code):\n",
    "    encoder = model_load(hash_code)\n",
    "    _, h = encoder(image)\n",
    "    _, h1 = encoder(image1)\n",
    "    distance_file_mname = f'distances_{hash_code}.pkl'\n",
    "    with open(os.path.join('./Datastore/Distances/', distance_file_mname), 'rb') as file:\n",
    "        distG = pickle.load(file)\n",
    "    cos = F.cosine_similarity(h, h1, dim=1, eps=1e-6)\n",
    "    cos_distH = F.relu((1-cos)*hash_code/2)\n",
    "    #print(distH)\n",
    "\n",
    "    sum_label = labels +labels1\n",
    "    #print(labels[0])\n",
    "    #print(labels1[0])\n",
    "    #print(sum_label)\n",
    "\n",
    "    union_label = (sum_label >= 1).sum().tolist()\n",
    "    intersection_label = (sum_label >= 2).sum().tolist()\n",
    "    #print(union_label)\n",
    "    #print(intersection_label)\n",
    "    g_distH = distG[union_label][intersection_label]\n",
    "\n",
    "    g_distH = torch.tensor(g_distH)\n",
    "    print('Groundtruth HD:', g_distH.item())\n",
    "    print('Predicted HD:', cos_distH.item())\n",
    "    print('-----------')\n",
    "    return cos_distH.item(), g_distH.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please specify the hash code length for HD comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparison between ground truth HD  and predicted HD:\n",
      "Groundtruth HD: 6\n",
      "Predicted HD: 5.220604419708252\n",
      "-----------\n",
      "Groundtruth HD: 4\n",
      "Predicted HD: 3.7795209884643555\n",
      "-----------\n",
      "Groundtruth HD: 8\n",
      "Predicted HD: 7.707073211669922\n",
      "-----------\n",
      "Groundtruth HD: 4\n",
      "Predicted HD: 4.11698579788208\n",
      "-----------\n",
      "Mean and Std, of Groundtruth HD: [5.5, 1.6583123951777]\n",
      "Mean and Std, of Predicted HD: [5.206046104431152, 1.5391860506020445]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hash_code_length =16\n",
    "print('comparison between ground truth HD  and predicted HD:')\n",
    "predicted_hd_12, g_distH_12 = HDCompare(x_1, x_2, y_1, y_2, hash_code=hash_code_length)\n",
    "predicted_hd_13, g_distH_13 = HDCompare(x_1, x_3, y_1, y_3, hash_code=hash_code_length)\n",
    "predicted_hd_14, g_distH_14 = HDCompare(x_1, x_4, y_1, y_4, hash_code=hash_code_length)\n",
    "predicted_hd_15, g_distH_15 = HDCompare(x_1, x_5, y_1, y_5, hash_code=hash_code_length)\n",
    "Predicted_distance_list = [predicted_hd_12, predicted_hd_13, predicted_hd_14, predicted_hd_15]\n",
    "G_distH_list = [g_distH_12, g_distH_13, g_distH_14, g_distH_15]\n",
    "print('Mean and Std, of Groundtruth HD:', [np.mean(G_distH_list), np.std(G_distH_list)])\n",
    "print('Mean and Std, of Predicted HD:', [np.mean(Predicted_distance_list), np.std(Predicted_distance_list)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Retrieval images (Figure 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import nDCG, aCG, mAPw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model_load(hash_code=48) #results in paper are produced using 48-bit gash code length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "galleryfolderpath ='./Dataset/gallery'\n",
    "queryfolderpath = './Dataset/query'\n",
    "gallery_files = os.listdir(galleryfolderpath)\n",
    "query_files = os.listdir(queryfolderpath)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Building Gallery .... \n",
      "\n",
      "\n",
      " Building Complete. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gallery = {}\n",
    "print(\"\\n\\n Building Gallery .... \\n\")\n",
    "with torch.no_grad():\n",
    "    # Process each gallery image\n",
    "    for img in gallery_files:\n",
    "        image_path = os.path.join(galleryfolderpath, img)\n",
    "\n",
    "        # Load and transform the image\n",
    "        image = np.load(image_path)\n",
    "        # transfer to one channel\n",
    "        if len(image.shape)!= 2:\n",
    "            image = np.mean(image,axis=-1)\n",
    "\n",
    "        image = Image.fromarray(image)\n",
    "        tensor_image = transform(image).unsqueeze(0).cuda()\n",
    "\n",
    "        # Pass the tensor through the medianet model\n",
    "        x_e, h = encoder(tensor_image)\n",
    "\n",
    "        # Store the result in the gallery dictionary\n",
    "        gallery[img] = torch.sign(h) #binary code\n",
    "\n",
    "        # Clean up\n",
    "        del tensor_image\n",
    "    print(\"\\n Building Complete. \\n\")\n",
    "\n",
    "    count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chest_X-ray_Atelectasis_73317.npy',\n",
       "  tensor([0.], device='cuda:0', grad_fn=<ReluBackward0>)),\n",
       " ('Chest_X-ray_Atelectasis_108334.npy',\n",
       "  tensor([2.0000], device='cuda:0', grad_fn=<ReluBackward0>)),\n",
       " ('Chest_X-ray_Atelectasis|Infiltration_35321.npy',\n",
       "  tensor([2.0000], device='cuda:0', grad_fn=<ReluBackward0>)),\n",
       " ('Chest_X-ray_Atelectasis_111942.npy',\n",
       "  tensor([2.0000], device='cuda:0', grad_fn=<ReluBackward0>)),\n",
       " ('Chest_X-ray_Atelectasis_9120.npy',\n",
       "  tensor([2.0000], device='cuda:0', grad_fn=<ReluBackward0>)),\n",
       " ('Chest_X-ray_Atelectasis|Effusion|Infiltration_91774.npy',\n",
       "  tensor([2.0000], device='cuda:0', grad_fn=<ReluBackward0>)),\n",
       " ('Chest_X-ray_Atelectasis|Pleural_Thickening_84179.npy',\n",
       "  tensor([2.0000], device='cuda:0', grad_fn=<ReluBackward0>)),\n",
       " ('Chest_X-ray_Atelectasis|Effusion|Fibrosis_23127.npy',\n",
       "  tensor([2.0000], device='cuda:0', grad_fn=<ReluBackward0>)),\n",
       " ('Chest_X-ray_Atelectasis|Pneumonia_72747.npy',\n",
       "  tensor([21.], device='cuda:0', grad_fn=<ReluBackward0>)),\n",
       " ('Chest_X-ray_Emphysema|Infiltration_109640.npy',\n",
       "  tensor([23.], device='cuda:0', grad_fn=<ReluBackward0>))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_name = 'Chest_X-ray_Atelectasis|Emphysema|Infiltration_27411.npy'\n",
    "query_image_path = os.path.join(queryfolderpath, q_name)\n",
    "# Load and transform the image\n",
    "query_image = np.load(query_image_path)\n",
    "# transfer to one channel\n",
    "if len(query_image.shape)!= 2:\n",
    "    query_image = np.mean(query_image,axis=-1)\n",
    "query_image = Image.fromarray(query_image)\n",
    "query_tensor_image = transform(query_image).unsqueeze(0).cuda()\n",
    "\n",
    "# Pass the tensor through the medianet model\n",
    "_, h_q = encoder(query_tensor_image)\n",
    "\n",
    "dist = {}\n",
    "for key, h1 in gallery.items():\n",
    "    #h1norm = torch.div(h1, torch.norm(h1, p=2))\n",
    "    #h2norm = torch.div(torch.sign(h_q), torch.norm(h_q, p=2))\n",
    "    #dist[key] = torch.pow(torch.norm(h1norm - h2norm, p=2), 2) * hash_code / 4\n",
    "    #print(h1)\n",
    "    #print(torch.sign(h_q))\n",
    "    cos = F.cosine_similarity(h1, torch.sign(h_q), dim=1, eps=1e-6)\n",
    "    dist[key] = F.relu((1-cos)*h_q.shape[1]/2)\n",
    "\n",
    "sorted_pool = sorted(dist.items(), key=operator.itemgetter(1))[0:10]\n",
    "sorted_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asimenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
